% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/extract_helpers.R
\name{shrink_by_hour}
\alias{shrink_by_hour}
\title{Shrink a dataframe with predictions at integer hours to one with interpolated predictions at non-integer hours}
\usage{
shrink_by_hour(dat, verbose = TRUE)
}
\arguments{
\item{dat}{A dataframe that contains FVCOM predictions (see \code{\link[fvcom.tbx]{expand_by_hour}} and \code{\link[fvcom.tbx]{extract}}). At a minimum, this should contain the following columns: 'hour_dbl', a numeric vector that defines the time of day in hours; 'hour', an integer vector that defines the hour for which predictions have been extracted; 'index_hour', an integer vector that defines the index in the FVCOM arrays for each hour; order', an integer vector that defines each unique, original row (prior to dataframe expansion by \code{\link[fvcom.tbx]{expand_by_hour}}); and 'wc', an numeric vector that defines the prediction extracted from FVCOM array(s).}

\item{verbose}{A logical input that defines whether or not to print messages to the console to monitor function progress.}
}
\value{
The function returns a dataframe, as inputted, but in which any predictions for non-integer hours have been interpolated from the predictions derived at the two surrounding hours. The 'hour' and 'index_hour' columns are dropped to avoid confusion.
}
\description{
FVCOM predictions are resolved hourly. For predictions at non-integer hours, \code{\link[fvcom.tbx]{expand_by_hour}} expands a dataframe with non-integer hours to include both surrounding integer hours, the predictions of which can be obtained with \code{\link[fvcom.tbx]{extract}}. This function is designed to 'shrink' the expanded dataframe back down to its original size by interpolating predictions between hours to generate a single prediction for each original timestamp.
}
\examples{
#### Step (1): Define a dataframe that defines the FVCOM predictions required
# Times, including non integer hours
timestamp <- as.POSIXct(c("2016-03-01 00:00:00",
                          "2016-03-02 00:02:00",
                          "2016-03-01 00:00:00"))
dat <- data.frame(timestamp = timestamp)
# Define columns required to extract FVCOM predictions (see fvcom.tbx::extract())
dat$hour_dbl <- lubridate::hour(dat$timestamp) +
                lubridate::minute(dat$timestamp)/60 +
                lubridate::second(dat$timestamp)/3600
dat$date_name <- date_name(dat$timestamp)
dat$mesh_ID <- as.numeric(as.character(dat_mesh_around_nodes$ID))[1]
# Examine dat
dat

#### Step (2): Implement expand_by_hour()
# ... to define integer hours at which to extract predictions
dat_exp <- expand_by_hour(dat)
# Examine dat_exp
dat_exp

#### Step (3): Extract predictions
# Define matches (see ?fvcom.tbx::extract)
match_hour <- data.frame(hour = 0:1, index = 1:2)
match_mesh <- data.frame(mesh = dat_nodexy$node_id, index = 1:length(dat_nodexy$node_id))
# Define path
path <- system.file("WeStCOMS_files/tidal_elevation",
                     package = "fvcom.tbx", mustWork = TRUE)
                     path <- paste0(path, "/")
# Extract predictions
dat_with_wc <- extract(dat = dat_exp,
                       match_hour = match_hour,
                       match_mesh = match_mesh,
                       dir2load = path)
# Examine dat_with_wc
dat_with_wc

#### Step (4): Implement shrink_by_hour() to interpolate predictions
dat_with_wc_interp <- shrink_by_hour(dat = dat_with_wc)
# Examine interpolated dataframe
dat_with_wc_interp
# Check interpolated value with interp_btw_hours()
interp_btw_hours(x = dat_with_wc$hour_dbl[2],
                 h1 = dat_with_wc$hour[2],
                 h2 = dat_with_wc$hour[3],
                 p1 = dat_with_wc$wc[2],
                 p2 = dat_with_wc$wc[3]
                 )

}
\seealso{
\code{\link[fvcom.tbx]{interp_btw_hours}} linearly interpolates predictions between hours.
}
\author{
Edward Lavender & Janneke Ransijn
}
